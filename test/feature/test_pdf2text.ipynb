{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_o_CckjBSzrH"
      },
      "outputs": [],
      "source": [
        "from difflib import SequenceMatcher\n",
        "from enum import Enum\n",
        "from pdf2image import convert_from_path\n",
        "from pytesseract import image_to_string\n",
        "import contextualSpellCheck as csc\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import pytesseract\n",
        "import spacy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "zF1xdhi0S5GY"
      },
      "outputs": [],
      "source": [
        "nlp = spacy.load(\"de_dep_news_trf\")\n",
        "CSC_IN_PIPELINE = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "P9RoEPdQTxfO"
      },
      "outputs": [],
      "source": [
        "class OcrPreparationException(Exception):\n",
        "    pass\n",
        "\n",
        "\n",
        "class OcrFailedOrNoTextFoundException(Exception):\n",
        "    pass\n",
        "\n",
        "\n",
        "class NlpNotReadyException(Exception):\n",
        "    pass\n",
        "\n",
        "\n",
        "class CscException(Exception):\n",
        "    pass\n",
        "\n",
        "\n",
        "class State(Enum):\n",
        "    INITIALIZED = 1\n",
        "    OCR_READY = 2 \n",
        "    OCR_DONE_CSC_NOT_READY = 3\n",
        "    NLP_CSC_READY = 4\n",
        "    NLP_CSC_DONE = 5\n",
        "    FINISHED = 6\n",
        "    \n",
        "\n",
        "class OCRContext:\n",
        "    def __init__(self, file_path: str, file_lang: str = \"deu\", verbose: bool = False):\n",
        "        if not os.path.exists(file_path):\n",
        "            raise FileExistsError\n",
        "        # Class variables from kwargs\n",
        "        self.file_path: str = file_path\n",
        "        self.file_lang: str = file_lang\n",
        "        self.verbose: bool = verbose\n",
        "        \n",
        "        # Additional variables necessary\n",
        "        self.content: list = list()\n",
        "        self.csc_initialized: bool = False\n",
        "        self.document_nlp = None\n",
        "        self.document_plain = None\n",
        "        self.state = State.INITIALIZED\n",
        "        self.text_ocr: str = str()\n",
        "        \n",
        "    def prepare_file(self):\n",
        "        if self.state == State.INITIALIZED:\n",
        "            self.document_plain = convert_from_path(self.file_path)\n",
        "            self.state = State.OCR_READY\n",
        "            if self.verbose:\n",
        "                print(f\"[i] State changed: {self.state}\")\n",
        "            \n",
        "        if self.state != State.OCR_READY:\n",
        "            raise OcrPreparationException\n",
        "\n",
        "    @staticmethod\n",
        "    def preprocess(image, show: bool = False, blocksize: int = 53, constant: int = 18):\n",
        "        image = cv2.resize(image, None, fx=2, fy=2, interpolation=cv2.INTER_LINEAR)\n",
        "        img_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "        image = img_gray\n",
        "        image = cv2.dilate(image, np.ones((7, 7), np.uint8))\n",
        "        img_bg = cv2.medianBlur(image, 21)\n",
        "        image = 255 - cv2.absdiff(img_gray, img_bg)\n",
        "        image = cv2.normalize(image, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8UC1)\n",
        "        image = cv2.adaptiveThreshold(image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, blocksize, constant)\n",
        "\n",
        "        # view image\n",
        "        if show:\n",
        "            cv2.imshow(\"Augmented Image\", image)\n",
        "            cv2.waitKey(0)\n",
        "            cv2.destroyAllWindows()\n",
        "\n",
        "        return image\n",
        "        \n",
        "    def perform_ocr(self, bsc):\n",
        "        if self.state == State.OCR_READY:\n",
        "            for page_number, page_data in enumerate(self.document_plain):\n",
        "                # Reset states\n",
        "                if self.state == State.NLP_CSC_DONE:\n",
        "                    self.state = State.OCR_READY\n",
        "                    if self.verbose:\n",
        "                        print(f\"[i] State changed: {self.state}\")\n",
        "\n",
        "                # TODO: Remove after testing\n",
        "                bs, c = bsc\n",
        "\n",
        "                page_data = self.preprocess(np.array(page_data), show=False, blocksize=bs, constant=c)\n",
        "\n",
        "                # Perform OCR\n",
        "                self.text_ocr = image_to_string(page_data, lang=self.file_lang)\n",
        "                \n",
        "                # Update states\n",
        "                if self.text_ocr != \"\":\n",
        "                    if not self.csc_initialized:\n",
        "                        self.state = State.OCR_DONE_CSC_NOT_READY\n",
        "                        if self.verbose:\n",
        "                            print(f\"[i] State changed: {self.state}\")\n",
        "                    else:\n",
        "                        self.state = State.NLP_CSC_READY\n",
        "                        if self.verbose:\n",
        "                            print(f\"[i] State changed: {self.state}\")\n",
        "                else:\n",
        "                    raise OcrFailedOrNoTextFoundException\n",
        "                \n",
        "                # Perform NLP and CSC\n",
        "                self.perform_nlp(page_number)\n",
        "            \n",
        "            self.state = State.FINISHED\n",
        "            if self.verbose:\n",
        "                print(f\"[i] State changed: {self.state}\")\n",
        "                \n",
        "    def perform_nlp(self, page_number):\n",
        "        if self.state == State.OCR_DONE_CSC_NOT_READY:\n",
        "            # Add contextualSpellChecker to pipeline\n",
        "            global CSC_IN_PIPELINE\n",
        "            if not CSC_IN_PIPELINE:\n",
        "                csc.add_to_pipe(nlp)\n",
        "                self.csc_initialized = True\n",
        "                self.state = State.NLP_CSC_READY\n",
        "                CSC_IN_PIPELINE = True\n",
        "                if self.verbose:\n",
        "                    print(f\"[i] State changed: {self.state}\")\n",
        "            else:\n",
        "                self.state = State.NLP_CSC_READY\n",
        "            \n",
        "        # Perform NLP\n",
        "        if self.state == State.NLP_CSC_READY:\n",
        "            self.document_nlp = nlp(self.text_ocr)\n",
        "        else:\n",
        "            raise NlpNotReadyException\n",
        "        \n",
        "        if self.document_nlp._.performed_spellCheck:    \n",
        "            page = dict()\n",
        "            page[\"number\"] = page_number + 1\n",
        "            page[\"content\"] = self.document_nlp._.outcome_spellCheck\n",
        "            self.content.append(page)\n",
        "            \n",
        "            if self.verbose:\n",
        "                print(f\"[*] Page: {page['number']}:\\n{page['content']}\")\n",
        "            \n",
        "            self.state = State.NLP_CSC_DONE\n",
        "            if self.verbose:\n",
        "                print(f\"[i] State changed: {self.state}\")\n",
        "        else:\n",
        "            raise CscException"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "id": "Z9CS2g_LUMPy",
        "outputId": "829a3904-78ae-403c-fd19-90ec7fbe1cab"
      },
      "outputs": [],
      "source": [
        "# Disable parallelism (better performance as classification takes too long\n",
        "# and tokenization process gets forked before finishing)\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
        "\n",
        "ratio = list()\n",
        "\n",
        "c_low = 10  # 1\n",
        "c_high = 20  # 35\n",
        "c_step = 1\n",
        "b_low = 45  # 3\n",
        "b_high = 55  # 51\n",
        "b_step = 2\n",
        "\n",
        "iteration = 0\n",
        "max_iterations = len(range(b_low, b_high, b_step)) * len(range(c_low, c_high, c_step))\n",
        "\n",
        "for c in range(c_low, c_high, c_step):\n",
        "    for bs in range(b_low, b_high, b_step):\n",
        "        iteration += 1\n",
        "        print(f\"[i] Iteration {iteration}/{max_iterations}\")\n",
        "\n",
        "        # Perform OCR, tokenize, perform spell check\n",
        "        bsc = (bs, c)\n",
        "\n",
        "        try:\n",
        "            ctx = OCRContext(file_path=\"../../resources/scans/sync/Benchmark.pdf\", verbose=False)\n",
        "            ctx.prepare_file()\n",
        "            ctx.perform_ocr(bsc=bsc)\n",
        "        except OcrFailedOrNoTextFoundException:\n",
        "            print(\"[!] No text found\")\n",
        "            ratio.append([bs, c, 0.0])\n",
        "            continue\n",
        "        except NlpNotReadyException:\n",
        "            print(\"[!] NLP/CSC Failed\")\n",
        "            ratio.append([bs, c, 0.0])\n",
        "            continue\n",
        "\n",
        "        # Diff result with transcript\n",
        "        with open(\"../../resources/transcript_valid.txt\", \"r\") as transcript:\n",
        "            transcript_txt = str()\n",
        "\n",
        "            while transcript.readline():\n",
        "                transcript_txt += transcript.readline()\n",
        "\n",
        "            ocr_txt = str()\n",
        "\n",
        "            for page in ctx.content:\n",
        "                ocr_txt += page[\"content\"]\n",
        "\n",
        "            diff = SequenceMatcher()\n",
        "            diff.set_seq1(transcript_txt)\n",
        "            diff.set_seq2(ocr_txt)\n",
        "            match = diff.ratio()\n",
        "            ratio.append([bs, c, match])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 620
        },
        "id": "Wfbv2C7dUQRt",
        "outputId": "8c1cde33-716d-4206-a182-2a1a08a1e705"
      },
      "outputs": [],
      "source": [
        "%matplotlib widget\n",
        "bs = [b for b, c, r in ratio]\n",
        "c = [c for b, c, r in ratio]\n",
        "r = [r for b, c, r in ratio]\n",
        "\n",
        "# Plot results\n",
        "ax = plt.figure().add_subplot(projection='3d')\n",
        "ax.scatter(xs=bs, ys=c, zs=r, zdir='z')\n",
        "ax.set_xlabel('Blocksize')\n",
        "ax.set_ylabel('Threshhold Constant')\n",
        "ax.set_zlabel('Match Ratio')\n",
        "ax.set_zlim(0, 1)\n",
        "\n",
        "plt.title(\"Sequence Match Ratio by OpenCV AdaptiveThreshold\")\n",
        "plt.ion()\n",
        "plt.show()\n",
        "\n",
        "print(f\"[i] Best ratio achieved: {np.max(np.array(r))}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
